\input{../header}

% \mode<beamer>{\usetheme{AnnArbor}}
\mode<beamer>{\usetheme{metropolis}}
\mode<beamer>{\metroset{block=fill}}
% \mode<beamer>{\usecolortheme{wolverine}}

\mode<beamer>{\setbeamertemplate{section in toc}[sections numbered]}
\mode<beamer>{\setbeamertemplate{subsection in toc}[subsections numbered indented]}

% \mode<beamer>{\usefonttheme{serif}}
\mode<beamer>{\setbeamertemplate{footline}}
\mode<beamer>{\setbeamertemplate{footline}[frame number]}
\mode<beamer>{\setbeamertemplate{frametitle continuation}[from second][\insertcontinuationcountroman]}
\mode<beamer>{\setbeamertemplate{navigation symbols}{}}

\mode<handout>{\pgfpagesuselayout{2 on 1}[letterpaper,border shrink=5mm]}

\newcommand\CHAPTER{4}
% \newcommand\answer[2]{\textcolor{blue}{#2}} % to show answers
% \newcommand\answer[2]{\textcolor{red}{#2}} % to show answers
 \newcommand\answer[2]{#1} % to show blank space

\title{\vspace{2mm} \link{https://jeswheel.github.io/4451_f25/}{Mathematical Statistics II}\\ \vspace{2mm}
The Bayesian Approach to Parameter Estimation}
\author{Jesse Wheeler}
\date{}

\setbeamertemplate{footline}[frame number]




\begin{document}

\maketitle

\mode<article>{\tableofcontents}

% \mode<presentation>{
%   \begin{frame}{Outline}
%     \tableofcontents
%   \end{frame}
% }

\section{Introduction}

\begin{frame}[allowframebreaks]{Bayesian Estimation}

\begin{itemize}
  \item Much of this work is based on \citet[][Section~8.6]{rice07}.
  \item We have already discussed the philosophy of Bayesian statistics.
  \item We start with a prior belief about parameter values, and update these beliefs using observed data.
  \item The resulting \alert{distribution} is called the \emph{posterior}, and it represents our updated belief after observing data. 
  \item This is very natural idea that is closely related to the idea of likelihood: likelihood quantifies some degree of belief about a parameter value.
\end{itemize}

\end{frame}

\section{Review}

\begin{frame}[allowframebreaks]{Some Review}
  \begin{itemize}
    \item Before we begin, we will first do a bit of review.
    \item In the context of Bayesian inference, we treat unknown parameter vectors as random variables, which I will denote $\Theta$.
    \item Thus, our probability model can be expressed as $f(x|\Theta = \theta)$, which we often shorten to $f(x|\theta)$.
  \end{itemize}
  
  \begin{block}{Bayes' Theorem}
    Let $X$ be the random vector representing observed data, and $\Theta$ the random parameter vector, and $x^*$ the observed data. Bayes Theorem states:
    \begin{align*}
    \pi_{\Theta|X}(\theta|x^*) &= \frac{f_{X|\Theta}(x^*|\theta)\pi_\Theta(\theta)}{f_X(x^*)} \\
    &= \frac{f_{X|\theta}(x^*|\theta)\pi_\Theta(\theta)}{\int f_{X|\Theta}(x^*|\tau)\pi_\Theta(\tau)\,d\tau}
    \end{align*}
    
    \mode<article>{
      \begin{itemize}
        \item There are a few things to note in the equation above. First, the likelihood function $L(\theta) = f(x^*|\theta)$ makes its presence on the right hand side of the equation.
        \item Next, the denominator is not a function of $\theta$. As a result, it is just a normalizing constant to ensure that the posterior is a proper probability distribution.
        \item With this in mind, we often say that the posterior distribution $\pi_{\Theta|X}(\theta|x^*)$ is a product of the likelihood $L(\theta)$ and the prior $\pi_{\Theta}(\theta)$.
        \item There is a large number of notations that are often used. For instance, the symbol $f$ is often used instead of $\pi$ as a function. The most common is perhaps:
        $$
        \pi(\theta|x) = \frac{f(x|\theta)\pi(\theta)}{\int f(x|\theta)\pi(\theta)\, d\theta}.
        $$
        \item The above notation does a bit of "function overload", but it is often clear from context and the symbols used as input what is meant.
      \end{itemize}
    }
    
  \end{block}
  
  \begin{itemize}
    \item As before, $f$ is taken to be either a pmf or pdf, depending on the problem.
  \end{itemize}
  
  \framebreak
  
  \begin{exampleblock}{Flipping 10 coins}
    Our friend hands us a coin from another country, and we want to estimate $\theta = p$, the probability that the coin lands heads. Suppose we flip a coin 10 times, and see $n$ heads. Find a Bayesian estimate for $\theta$.
    
    \mode<article>{
      \begin{itemize}
        \item The probability model describing the data is Binomial$(N = 10, p = \theta)$, which has mass function:
        $$
        f_{X|\Theta}(n | \theta) = \binom{N}{n}\theta^n(1-\theta)^{N-n}.
        $$
        \item After picking the model for the data $f(x|\theta)$, the next step is to define our prior belief about the coin, characterized by $\pi_\Theta(\theta)$.
        \item A natural prior might be: ``I know nothing about the coin, all probabilities are possible". Then, our prior would be uniform:
        $$
        \pi_\Theta(\theta) = 1(0 \leq \theta \leq 1)
        $$
        \item Thus, we previously found the posterior to be:
        \begin{align*}
        \pi(\theta | n) &= \frac{\binom{N}{n}\theta^n(1-\theta)^{N-n}}{\int^1_0 \binom{N}{n}\theta^n(1-\theta)^{N-n} \, d\theta} 1[0\leq \theta \leq 1]\\
        &=\frac{\Gamma(N + 2)}{\Gamma(n+1)\Gamma(N-n+1)}\theta^n(1-\theta)^{N-n} 1[0\leq \theta\leq 1]
        \end{align*}
        \item We then demonstrated that this corresponds to a beta distribution. Thus:
        $$
        \Theta | X = n \sim \text{Binom}(\text{Beta}(n + 1, N - n + 1))
        $$
        \item Now our belief about $\Theta$ has been updated using the data $X = n$. This belief is represented not be a single point, but an entire distribution. 
        \item There are multiple ways to get a single point estimation.
        \item One idea is the mean of the posterior, $E[\Theta|X = n]$. In this case, the mean of the Beta distribution is known, and we find:
        $$
        E[\Theta | X = n] = \frac{n + 1}{N+2}.
        $$
        As mentioned, this is like a regularized version of the MLE $(n/N)$, as the estimate is ``pulled" toward the center $\theta = 0.5$.
        \item Another common approach is similar to what we did with the MLE: if the posterior represents our updated belief as a distribution, why don't we let our point estimate be the \emph{maximum} of that belief? In this setting, the maximum of a probability density is the \emph{mode}. The mode of the Beta$(\alpha, \beta)$ distribution is given by:
        $$
        \frac{\alpha - 1}{\alpha + \beta - 2}.
        $$
        \item For our specific posterior, this implies that the mode is:
        $$
        \hat{\theta} = \frac{(n + 1) - 1}{(n + 1) + (N - n + 1) - 2} = \frac{n}{M}.
        $$
        \item Note that the mode in this case matches the MLE!
        \item The mode of the posterior distribution is called the Maximum A Posteriori (MAP) estimate. This is a common choice for a point estimate, in particular by Frequentists who use Bayesian methods to solve a given problem.
        There are some advantages and disadvantages of this approach, one being that it is not a properly weighted version of our belief; it also lacks some of the proprieties and guarantees that Bayesian statisticians like. The MAP can also be difficult (or impossible) to compute in many situations, whereas the posterior mean and median can readily be approximated using samples from a distribution.
        \item Another possible point estimate is the median of the posterior distribution. There's not a closed-form expression for the median of a Beta-distribution, but it can be calculated via software.
      \end{itemize}
    }
    
  \end{exampleblock}
  
  \framebreak
  
  \begin{itemize}
    \item Even in the simple problem above, we see two of the primary challenges with Bayesian parameter estimation:
    \begin{itemize}
      \item How do we choose the prior distribution $\pi(\theta)$? A generally safe and accepted approach is a uniform prior. However, this formally only exists if $\theta$ is bounded, which is not always the case. Also, it represents a prior belief: given a new coin, do we really think all values of $p$ are equally likely, or maybe values close to $p = 0.5$ are more likely than extreme values $p = 0, 1$? Since the prior represents our beliefs about $\theta$, is a uniform prior actually appropriate? If it isn't appropriate, how exactly should we specify the prior?
      \item Even in this very simple model and prior, the denominator $f(x)$ was difficult to compute. What about more complex models and priors? A large amount of Bayesian computation and theory is dedicated to solving this problem.
    \end{itemize}
  \end{itemize}
  
  \framebreak
  
  \begin{block}{Proposition: the MAP and MLE}
    Let $\theta$ be a parameter of interest, and $x^*$ the observed data. If our prior distribution is proportional to $1$, i.e., $\pi(\theta) \propto 1$ (which is effectively a uniform prior on a bounded interval), then
    $$
    \hat{\theta}_{\text{MAP}} = \hat{\theta}_{\text{MLE}}.
    $$
    
    \mode<article>{
      \begin{itemize}
        \item A proof sketch is given in class, but is left as an exercise in these notes.
      \end{itemize}
    }
    
  \end{block}
  
  \begin{itemize}
    \item This is true for the Coin-tossing example; look back at the likelihood function and posterior, and use R to plot them both.
  \end{itemize}
  
\end{frame}

\section{Examples}

\begin{frame}[allowframebreaks]{Bayesian point-estimate examples}
  \begin{exampleblock}{Poisson model}
    Suppose we have observations $n$ observations, which we wish to model as IID Poisson$(\lambda)$. Find a Bayesian estimate of $\Lambda = \lambda$ given the observed data $x^*$.
    
    \mode<article>{
      \begin{itemize}
        \item First we find the density of $X | \Lambda = \lambda$, which begins with finding the density of a single observation $X_i | \Lambda = \lambda$:
        $$
        f_{X_i|\Lambda}(x| \lambda) = \frac{\lambda^x e^{-\lambda}}{x!}, \quad x \in \{0, 1, 2, \ldots\}.
        $$
        \item Under the IID assumption, the joint density of $X$ is:
        \begin{align*}
        f_{X|\Lambda}(x|\lambda) &= \prod_{i = 1}^n f_{X_1|\Lambda}(x_i | \lambda) \\
        &= \prod_{i = 1}^n \frac{\lambda^{x_i} e^{-\lambda}}{x_i!} \\
        &= \frac{\lambda^{\sum_{i = 1}^n x_i} e^{-n\lambda}}{\prod_{i = 1}^n x_i!}.
        \end{align*}
        \item Now we want to find the posterior of $\Lambda | X$, which is given by:
        $$
        f_{\Lambda | X}(\lambda | x^*) = \frac{\lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda}\, f_\Lambda(\lambda)}{\int \lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda}\, f_\Lambda(\lambda) \, d\lambda}.
        $$
        Above, $f_\Lambda(\lambda)$ is the prior distribution of $\Lambda$, and the product $\prod_{i = 1}^N x_i!$ canceled out as it was in both the numerator and denominator.
        \item Now there are two remaining steps, the parts that are often challenging in Bayesian estimations: (1) choosing the prior, (2) computing the integral in the denominator.
        \item We will consider two different approaches for picking the prior. The first is the traditional / orthodox Bayesian, who takes very seriously the philosophy that the prior distribution captures their prior opinion.
        \item In this orthodox approach, the prior density $f_\Lambda(\lambda)$ should be specified \emph{before} ever seeing the data (the whole point is this is our prior belief before observing data).
        \item This itself is not an easy task; even in this scenario, we may pick a prior based both on belief, and convenience.
        \item That is, suppose that we believe the prior mean $E[\Lambda] = \mu = 15$, with variance $\Var(\Lambda) = \sigma^2 = 25$. There's a lot of distributions out there that have these features, but we will pick the Gamma distribution because it will be mathematically convenient.
        \item Since the Gamma$(\alpha, \beta)$ has mean $15 = \alpha/\beta$ and variance $25 = \alpha / \beta^2$, we can solve and get our prior density for $\Lambda$ as:
        $$
        \Lambda \sim \text{Gamma}(\alpha = 9, \beta = 3/5).
        $$
        \item Note that the choice of the mean and variance can (and should) be aided by plotting the function, and typically the Gamma distribution has parameter values $\alpha$ and $\lambda$, but we're already using $\lambda$ for something else here.
        \item Thus, the prior density is:
        $$
        f_\Lambda(\lambda) = \frac{\beta^\alpha}{\Gamma(\alpha)}\lambda^{\alpha - 1}e^{-\beta\lambda}, \quad \lambda > 0.
        $$
        \item After canceling constants (anything not involving $\lambda$) and combining like-terms, we get:
        $$
        f_{\Lambda | X}(\lambda | x^*) = \frac{\lambda^{\sum_{i = 1}^n x^*_i + \alpha - 1}e^{-(n + \beta)\lambda}}{\int_{0}^\infty \lambda^{\sum_{i = 1}^n x^*_i + \alpha - 1}e^{-(n + \beta)\lambda}\,d\lambda}
        $$
        \item Now we encounter a common trick (and the reason we picked a Gamma prior). Note that the denominator is \emph{only} a function of $x$, and not $\lambda$. Thus,
        \begin{align*}
        f_{\Lambda | X}(\lambda | x^*) &\propto \lambda^{\sum_{i = 1}^n x^*_i + \alpha - 1}e^{-(n + \beta)\lambda} \\
        &= \lambda^{\text{something}}e^{-\text{something}\lambda}.
        \end{align*}
        Here, $\lambda$ is the variable of interest (not a constant). Thus, we want to compare this statement to other \emph{kernels} that look like:
        $$
        f(x) \propto x^{a}e^{-b\lambda}.
        $$
        \item This kernel matches that of the standard Gamma$(\gamma, \zeta)$ distribution:
        $$
        f(x) \propto x^{\gamma-1}e^{-\zeta x}
        $$
        (again, swapping variables $\gamma$, $\zeta$ for $\alpha$ and $\lambda$ for obvious reasons).
        \item We can immediately conclude that the posterior MUST be a Gamma distribution (since it will integrate to one). What is left is to pick the corresponding parameter values. To do this, we must have:
        $$
        \gamma - 1 = \sum_{i = 1}^n x^*_i + \alpha - 1 \implies \gamma = \sum_{i = 1}^n x^*_i + \alpha, 
        $$
        and
        $$
        -\zeta = -(n + \beta) \implies \zeta = n + \beta.
        $$
        Thus, the posterior distribution is:
        $$
        \Lambda | X = x^* \sim \text{Gamma}\big(\sum_{i = 1}^n x^*_i + \alpha, n + \beta\big).
        $$
        \item Then all we need to do is plug is our specific data values $x_i^*$, and the specific values of our prior $\alpha = 9$, $\beta = 3/5$.
        \item From this, we can get various point estimates: posterior mean, MAP, or posterior median. We can also talk about posterior variance if we want.
        \item \textbf{This trick of avoiding calculating the integral in the denominator is extremely common, and it will appear again. Make sure this makes sense to you}.
      \end{itemize}
    }
    
  \end{exampleblock}
  
  \framebreak
  
  \begin{exampleblock}{Poisson posterior, uniform prior}
    Revisit the Poisson$(\lambda)$ model, while taking the alternative approach of using a uniform prior.
    
    \mode<article>{
      \begin{itemize}
        \item The setup for the problem is the exact same, so note that the posterior distribution is:
        $$
        f_{\Lambda | X}(\lambda | x^*) = \frac{\lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda}\, f_\Lambda(\lambda)}{\int \lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda}\, f_\Lambda(\lambda) \, d\lambda}.
        $$
        \item Now suppose we really don't have a good guess for the parameter $\lambda$, or we want to more utilitarian / noncommittal approach. Now what?
        \item The default is a uniform probability, but the possible values of $\lambda$ is the interval $(0, \infty)$; we can't have a uniform prior on this interval (it doesn't exist)
        \item Instead, we will feign confidence that $\lambda$ must be smaller than some fixed number based on the problem at hand. For instance, maybe $0 < \lambda \leq 100$ is reasonable.
        \item Then, the prior would be:
        $$
        f_\Lambda(\lambda) = \frac{1}{100} 1(0 < \lambda \leq 100),
        $$
        and the posterior would be:
        \begin{align*}
        f_{\Lambda | X}(\lambda | x^*) &= \frac{\frac{1}{100}\lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda}}{\frac{1}{100}\int_0^{100} \lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda} \, d\lambda}1(0 < \lambda \leq 100)\\
        &= \frac{\lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda}}{\int_0^{100} \lambda^{\sum_{i = 1}^n x^*_i} e^{-n\lambda} \, d\lambda} 1(0 < \lambda \leq 100).
        \end{align*}
        \item In this case, we can't just do the denominator-integration trick! It looks very similar, because the denominator is still a constant, and the kernel in the numerator looks very similar to a Gamma kernel, \textbf{but} we have a new bound $0 < \lambda \leq 100$ that makes it distinct from the Gamma distribution, since the Gamma distribution has support on $(0, \infty)$.
        \item Unfortunately, there is not an easy way to compute the integral either (partly because of the bound). Thus, the integral needs to be computed numerically.
        \item For now, we will just use the \code{integrate} function in R, which is really good at integrating univariate functions.
        \item The posterior mean can similarly be found using a numeric integration technique, and posterior mode can be found using numeric optimization strategies covered in the last set of lecture notes.
      \end{itemize}
    }
    
  \end{exampleblock}

\end{frame}

\begin{frame}[allowframebreaks,fragile]{Real-data example: Poisson Distribution}

\begin{itemize}
  \item Now let's look at a real-data example. These data are the 23 observations from the asbestos-filter problem.
\end{itemize}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{x} \hlkwb{<-} \hlkwd{c}\hldef{(}
  \hlnum{31}\hldef{,} \hlnum{29}\hldef{,} \hlnum{19}\hldef{,} \hlnum{18}\hldef{,} \hlnum{31}\hldef{,} \hlnum{28}\hldef{,} \hlnum{34}\hldef{,} \hlnum{27}\hldef{,} \hlnum{34}\hldef{,} \hlnum{30}\hldef{,} \hlnum{16}\hldef{,} \hlnum{18}\hldef{,}
  \hlnum{26}\hldef{,} \hlnum{27}\hldef{,} \hlnum{27}\hldef{,} \hlnum{18}\hldef{,} \hlnum{24}\hldef{,} \hlnum{22}\hldef{,} \hlnum{28}\hldef{,} \hlnum{24}\hldef{,} \hlnum{21}\hldef{,} \hlnum{17}\hldef{,} \hlnum{24}
\hldef{)}
\hldef{x}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
 [1] 31 29 19 18 31 28 34 27 34 30 16 18 26 27 27 18 24 22
[19] 28 24 21 17 24
\end{verbatim}
\end{kframe}
\end{knitrout}


\framebreak

\begin{exampleblock}{Comparing Estimates}
  Using the data above, compare estimates using the MoM, MLE, and the two Bayesian approaches, as well as the corresponding errors related to these estimates.
\end{exampleblock}

\end{frame}

\begin{frame}[allowframebreaks]{Posteriors and Likelihood}
  \begin{itemize}
    \item In the problem above, we saw that we get very similar estimates using MLE or Bayesian approaches, regardless of which prior we picked.
    \item We can argue why this will often be the case, especially for IID data.
    \item Previously, we saw:
    $$
    \text{posterior} \propto \text{likelihood} \times \text{prior}
    $$
    \item When $n$ gets large, the likelihood dominates in this equation. In the IID case:
    $$
    \text{likelihood} = \prod_{i = 1}^n f(x^*_i | \theta).
    $$
    \item In particular, each new data point scales the likelihood larger and larger, to the point where the prior has little impact on the posterior distribution.
    \item See the accompanying Lecture 4 R code for a visual demonstration of this using the Poisson distribution.
  \end{itemize}
\end{frame}

\section{Introduction to Numeric Integration}

\begin{frame}[allowframebreaks]{Numeric Integration}
  \begin{itemize}
    \item As we saw in the previous example, one of the primary challenges of Bayesian estimation is the integration in the denominator of the posterior.
    \item Bayesian statistics has really exploded since the late 20th century, largely thanks to improved computational tools that help with the numeric integration.
    \item For this set of lectures, we only briefly introduce this topic. Depending on time and interest, we can explore this topic more later in the semester.
  \end{itemize}
\end{frame}

\section{Choice of Priors}

\begin{frame}[allowframebreaks]{Conjugate priors}
  \begin{itemize}
    \item The Poisson$(\lambda)$ example showed two main approaches:
    \begin{itemize}
      \item The traditional (subjective) Bayesian, who takes seriously the choice of prior, and chose a Gamma density to aid computations.
      \item The utilitarian (objective) Bayesian, who picked an uninformative prior.
    \end{itemize}
    \item The former approach was aided by what is known as a \alert{conjugate prior}.
  \end{itemize}
  
  \framebreak
  
  \begin{block}{Definition: Conjugate priors}
    Suppose the prior distribution belongs to a family of distributions, $G$, and the data come from a family of distributions $H$.
    
    $G$ is said to be conjugate to $H$ if the posterior is in the family $G$.
  \end{block}
  
  \begin{itemize}
    \item Example: If the data-model is Poisson$(\lambda)$, then the family $H$ is the family of Poisson distributions. The Gamma family ($G$) of distributions is conjugate to the Poisson family, because if Gamma is selected as the prior distribution, then the posterior distribution (under data model $H$) is still Gamma $(G)$, with updated parameters. 

  \framebreak
    
    \item Much of the Bayesian statistics of the 20th century relied on conjugate priors to help with integration, or were confined to models with very few parameters.
    \item Recent developments in computing, both hardware, software, and theory of Bayesian computing, has enabled fitting much more complex models using arbitrary priors.
    \item Still, it's worth discussing conjugate priors, and we will provide a few examples.
    
  \end{itemize}
  
\end{frame}

\begin{frame}[allowframebreaks]{Jeffrey's priors}
  \begin{itemize}
    \item TODO
  \end{itemize}
\end{frame}

\section{Hierarchical Bayes}

\begin{frame}[allowframebreaks]{Hierarchical Bayes}

  \begin{itemize}
    \item The idea behind Hierarchical Bayes is simple: our model $f$ depends on parameters $\theta$.
    \item We can get a prior for $\theta$, $\pi(\theta)$.
    \item The prior itself depends on parameters, say $\pi(\theta;\theta_1)$.
    \item How do we choose $\theta_1$? Sometimes we might know $\theta_1$, but sometimes not.
    \item In a pure Bayesian paradigm, if we don't know the value of $\theta_1$, then it is also a random variable $\Theta_1$, and we should put a prior on this as well!
    \item In some way, this allows us to be less-committal about the parameters in the prior model, and instead allow the data to inform our choice of priors (to some degree).
    \item Philosophically, this situation naturally arises if we want to pick a conjugate prior for $\Theta$, but are not committal about the \alert{hyperparameters} $\Theta_1$ that define the distribution of $\Theta$.
  
    \item We could continue doing this many times if we wanted!
    \item The prior for $\Theta_1$ might depend on parameters $\theta_2$, which we model as a random variable $\Theta_2$, $\ldots$.
    \item This leads to a model for $(X, \Theta, \Theta_1, \ldots, \Theta_N)$.
    \item However, there is a conditional structure to this model:
    $$
    \Theta_N \longrightarrow \Theta_{N-1} \longrightarrow \ldots \longrightarrow \Theta \longrightarrow X.
    $$
    \item Thus, $X$ depends only on $\Theta$, and $\Theta_n$ only on $\Theta_{n+1}$:
    % $$
    % X | \Theta = \theta \sim f(x | \theta), \,\, \Theta | \Theta_1 = \theta_1 \sim \pi_{1}(\theta|\theta_1), \ldots, \Theta_{N - 1} | \Theta_{N} = \theta_{N} = \pi_{N-1}(\theta_{N-1} | \theta_{N})\, \Theta_N \sim \pi_N(\theta_n).
    % $$
    $$
    X | \Theta = \theta \sim f(x | \theta), \,\, \Theta | \Theta_1 = \theta_1 \sim \pi_{1}(\theta|\theta_1)\,\, \ldots \,\, \Theta_N \sim \pi_N(\theta_n).
    $$
    
    \framebreak
    
    \item Using rules of marginal probability and conditional probability, then
    \begin{align*}
      \pi(\theta) &= \int \pi(\theta, \theta_1, \ldots, \theta_N) \, d\theta_{1:N} \\
      &= \int \pi(\theta | \theta_{1:N}) \pi(\theta_{1:N}) \, d\theta_{1:N} \\
      &= \int \pi(\theta|\theta_1) \pi(\theta_1 | \theta_{2:N})\pi(\theta_{2:N})\, d\theta_{1:N}\\
      &= \vdots \\
      &= \int \pi(\theta|\theta_1)\pi(\theta_1|\theta_2) \ldots, \pi(\theta_{N-1}|\theta_N)\pi(\theta_N) \, d\theta_{1:N}
    \end{align*}
    
    \item Thus, the hierarchical model is functionally equivalent to the standard Bayesian model:
    $$
    X|\Theta = \theta \sim f(x|\theta)\quad \Theta \sim \pi(\theta),
    $$
    where $\pi(\theta)$ is given by the integral above.

    \item Why would we want to do this?
    \begin{enumerate}
      \item Sometimes the data / problem give rise to a natural hierarchical structure, and this idea will be useful. Here, we might actually be interested in the hyperparameters $\theta_1, \ldots, \theta_N$.
      \item We can now be less committal about our priors, while still using desirable structures.
      \item It can sometimes aid computations. 
    \end{enumerate}

  \end{itemize}

\framebreak

\begin{exampleblock}{Trivial case: hierarchical Normal-Normal}
  Suppose that the data $X_i$ are iid $N(\theta, 1)$. Set a prior for $\theta$ as $\Theta|\Theta_1 = \theta_1 \sim N(\theta_1, 1)$, and $\Theta_1 \sim N(0, 1)$.

  \mode<article>{
    \begin{itemize}
      \item This model seems rather odd, unless there is a good reason to get the posterior $(\Theta, \Theta_1) | X = x^*$.
      \item Otherwise, we can show that the \emph{hyperparameter} $\Theta_1$ can be eliminated from the model.
      \item In particular, consider the marginal distribution of $\Theta$:
      $$
      \pi_\Theta(\theta) = \int \pi_{\Theta | \Theta_1}(\theta | \theta_1) \pi_{\Theta_1})(\theta_1) \, d\theta_1,
      $$
      \item Some algebra (i.e., completing the square in the exponential terms), shows that this is equivalent to: $\Theta \sim N(0, 2)$.
      \item Thus, if we're not interested in the hyper-parameters themselves, then what we are interested in is:
      $$
      \Theta | X = x^*,
      $$
      which can just be calculated by setting the prior $\Theta \sim N(0, 2)$, and following the standard Bayesian approach.
    \end{itemize}
  }

\end{exampleblock}

\framebreak

\begin{exampleblock}{More realistic example: Coin-toss experiment}
  Suppose your friend gives you a coin from another country, and you want to estimate $\theta = p$, the probability of heads. Thus, in $N$ tosses, the natural model for $X$, the number of heads, $X \sim \text{Bin}(N, \theta)$. You're believe that the proportion is close to $1/2$, but not quite sure.
  A nice prior would be the Beta$(\alpha, \beta)$-distribution, since it is conjugate for the binomial family.
  
  
  If $\Theta \sim \text{Beta}(\alpha, \beta)$, then $E[\Theta] = \frac{\alpha}{\alpha + \beta}$. Thus, if I want a prior centered at $1/2$, I can pick: $\theta_1 = \alpha = \beta$, and $E[\Theta] = \theta_1 / 2\theta_1 = 1/2$.
  We can now give a prior for $\Theta_1$.
  
\end{exampleblock}

\end{frame}

\begin{frame}[allowframebreaks,fragile]{Hierarchical Bayes (continued)}
  \begin{itemize}
    \item For now, we will restrict our choices of $\Theta_1$ to be integers.
  \end{itemize}
  

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{Theta} \hlkwb{<-} \hlkwd{seq}\hldef{(}\hlnum{1e-8}\hldef{,} \hlnum{1}\hlopt{-}\hlnum{1e-8}\hldef{,} \hlkwc{length.out} \hldef{=} \hlnum{1000}\hldef{)}
\hldef{B1} \hlkwb{<-} \hlkwd{dbeta}\hldef{(Theta,} \hlnum{1}\hldef{,} \hlnum{1}\hldef{)}
\hldef{B2} \hlkwb{<-} \hlkwd{dbeta}\hldef{(Theta,} \hlnum{2}\hldef{,} \hlnum{2}\hldef{)}
\hldef{B3} \hlkwb{<-} \hlkwd{dbeta}\hldef{(Theta,} \hlnum{3}\hldef{,} \hlnum{3}\hldef{)}
\hldef{B5} \hlkwb{<-} \hlkwd{dbeta}\hldef{(Theta,} \hlnum{5}\hldef{,} \hlnum{5}\hldef{)}
\hldef{B10} \hlkwb{<-} \hlkwd{dbeta}\hldef{(Theta,} \hlnum{10}\hldef{,} \hlnum{10}\hldef{)}

\hlkwd{plot}\hldef{(}\hlkwc{x} \hldef{= Theta,} \hlkwc{y} \hldef{= B1,} \hlkwc{type} \hldef{=} \hlsng{'l'}\hldef{,} \hlkwc{ylim} \hldef{=} \hlkwd{c}\hldef{(}\hlnum{0}\hldef{,} \hlnum{3.5}\hldef{),} \hlkwc{col} \hldef{=} \hlsng{"#c6dbef"}\hldef{,} \hlkwc{xlab} \hldef{=} \hlsng{"Theta"}\hldef{,} \hlkwc{ylab} \hldef{=} \hlsng{"density"}\hldef{)}
\hlkwd{lines}\hldef{(}\hlkwc{x} \hldef{= Theta,} \hlkwc{y} \hldef{= B2,} \hlkwc{type} \hldef{=} \hlsng{'l'}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{'#9ecae1'}\hldef{)}
\hlkwd{lines}\hldef{(}\hlkwc{x} \hldef{= Theta,} \hlkwc{y} \hldef{= B3,} \hlkwc{type} \hldef{=} \hlsng{'l'}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{'#6baed6'}\hldef{)}
\hlkwd{lines}\hldef{(}\hlkwc{x} \hldef{= Theta,} \hlkwc{y} \hldef{= B5,} \hlkwc{type} \hldef{=} \hlsng{'l'}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{'#3182bd'}\hldef{)}
\hlkwd{lines}\hldef{(}\hlkwc{x} \hldef{= Theta,} \hlkwc{y} \hldef{= B10,} \hlkwc{type} \hldef{=} \hlsng{'l'}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{'#08519c'}\hldef{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{tmp/figure/unnamed-chunk-3-1} 

}


\end{knitrout}


\framebreak
  
  
  \begin{itemize}
    \item As $\theta_1$ grows, the variance of $\Theta$ shrinks at a rate $O(\theta_1)$.
    \item Thus, to be noncommittal about our prior on $\Theta$, we will set a \alert{hyperprior} on $\Theta_1$ that has more weight on smaller values of $k$:
    $$
    \pi_{\Theta_1}(k) = \frac{1}{2\log (2) k(2k-1)},\, \quad k \in \{1, 2, \ldots\}
    $$
    \item This hyper-prior was selected somewhat out of convenience (The Catalan Numbers), which will allow us to get the marginal prior of $\Theta$:
    
    $$
    \pi(\theta) = \sum_{k = 1}^\infty \pi_{\Theta|\Theta_1}(\theta | k)\pi_{\Theta_1}(k) = \frac{1 - |1 - 2\theta|}{4\log(2) \theta(1 - \theta)}, \quad 0<\theta<1
    $$

    \framebreak

    \mode<article>{

      \begin{proof}
        \item The proof relies primarily on the Binomial Theorem. Some algebraic manipulation has already been done for us in the derivation of the Catalan numbers \citep{wikiCatalan}.
        
        \begin{align*}
          \pi(\theta) &= \sum_{k = 1}^\infty \pi_{\Theta|\Theta_1}(\theta | k)\pi_{\Theta_1}(k) \\
          &= \sum_{k = 1}^\infty \frac{\theta^{k-1}(1 - \theta)^{k-1}}{B(k, k)}\frac{1}{2\log(2)k(2k-1)}
        \end{align*}
        
        \item Since we picked $\theta_1 = k$ to be an integer (replacing with $k$ because the notation will be easier), 
        $$
        B(k, k) = \frac{\Gamma(k)\Gamma(k)}{\Gamma(2k)} = \frac{(k-1)!(k-1)!}{(2k-1)!}.
        $$
        thus,
        \begin{align*}
          \pi(\theta) &= \sum_{k = 1}^\infty \frac{\theta^{k-1}(1-\theta)^{k-1}(2k-1)!}{(k-1)!(k-1)!2\log(2)k(2k-1)} \\
          &= \frac{1}{2\log 2}\sum_{k = 1}^\infty \binom{2k-1}{k-1}\frac{\theta^{k-1}(1-\theta)^{k-1}}{(2k-1)} \\
          &= \frac{1}{2\log 2} \sum_{j = 0}^\infty \binom{2j + 1}{j}\frac{\big(\theta(1-\theta)\big)^j}{2j+1},
        \end{align*}
        where the second inequality uses the identity:
        $$
        \binom{2k-1}{k-1} = \frac{(2k-1)!}{(k-1)!(k-1)!k},
        $$
        and then we made the substitution $j = k - 1$ to get the third equality.
        \item Now if we make the substitution $\theta(1-\theta) = x$, such that $0 \leq x \leq 1/4$, then we get:
        $$
        \pi(\theta) = \frac{1}{2\log 2}\sum_{j = 0}^\infty \frac{1}{j+1}\binom{2j}{j}x^j = \frac{1}{2\log 2} c(x),
        $$
        where $c(x)$ is the generating unction for the Catalan numbers:
        $$
        c(x) = \frac{1-\sqrt{1 - 4x}}{2x}.
        $$
        \item Replacing $x = (\theta)(1-\theta)$, and noting that $1-4(\theta)(1-\theta) = (1-2\theta)^2$, we can then simplify to:
        $$
        \pi(\theta) = \frac{1-|1-2\theta|}{4\log(2) \theta(1-\theta)}, \quad 0 \leq \theta \leq 1.
        $$
        
      \end{proof}
    }
    \item In this case, we can get a closed-form expression for $\pi(\theta)$, but as you can tell, it can often get very difficult to do this mathematically.
    \item Thus, while the hierarchical structure is equivalent to just setting $\pi(\theta)$ as our prior (and not worrying about hierarchical model), this additional structure can aid in computations.
    
    \item If we are looking to estimate, for instance, the posterior mean:
    $$
    E_{\Theta|X}[\Theta],
    $$
    Then the law of total expectation gives:
    $$
    E_{\Theta|X}[\Theta|X] = E_{\Theta_1|X}\big[E_{\Theta|\Theta_1, X}[\Theta|\Theta_1, X]\big].
    $$
    \item Thus, the calculation of the posterior mean of $\Theta|X$ can be done without needing explicit form of the posterior $\Theta|X$, which can simplify the problem. 
    
    \item Our particular choice of likelihood and prior makes it easy to calculate the marginal-likelihood of $\Theta_1 = k$:
    \begin{align*}
    \pi_{X|\Theta_1}(x|k) &= \int_0^1 f(x|\theta, k)\pi_{\Theta|\Theta_1}(\theta; k)\, d\theta \\
    &= \binom{N}{x}\frac{B(x + k, N - x + k)}{B(k, k)}.
    \end{align*}
    
    \item Also, The Beta distribution was picked because it is conjugate, so the posterior mean $\Theta|\Theta_1 = k, X$ is readily available:
    $$
    E_{\Theta|\Theta_1 = k, X} = \mu_k = \frac{x + k}{N + 2k}.
    $$
    \item Now we need to take the expectation of this, with respect to the marginal posterior (un-normalized weights) $\pi_{\Theta_1|x}(k|x)$:
    \begin{align*}
    \pi_{\Theta_1|x}(k|x) &\propto w_k \\
    &= \pi_{X|\Theta_1}(x|k)\pi_{\Theta_1}(k) \\
    &= \frac{B(x + k, N - x + k)}{2\log(2)B(k, k)k(2k-1)}.
    \end{align*}
    \item Then, the normalized weights are:
    $$
    \bar{w}_k = \frac{w_k}{\sum_j w_j} = p(k | x),
    $$
    and the posterior mean is:
    $$
    E[\Theta | x] = \sum_{k = 1}^\infty \bar{w}_k \mu_k.
    $$
    \item For this particular example, the sum can be calculated exactly. However, we can also approximate this using software by taking the first $K$ partial sums. Check out the provided HB-code R code.
  \end{itemize}
  
  
  % $$
  % \pi(p) = \sum_{k = 1}^\infty \frac{p^{k-1}(1 - p)^{k-1}}{B(k, k)}\frac{1}{2\log(2)k(2k-1)} = \frac{1 - |1 - 2p|}{4\log(2)p(1- p)}
  % $$
  
\end{frame}

\section{Empirical Bayes}

\begin{frame}[allowframebreaks]{Empirical Bayes}
  TODO
\end{frame}

\section{Uncertainty quantification}

\begin{frame}[allowframebreaks]{Uncertainty in Bayes estimates}
  \begin{itemize}
    \item TODO
  \end{itemize}
\end{frame}

\newcommand\acknowledgments{
\begin{itemize}
\item   Compiled on {\today} using \Rlanguage version 4.5.2.
\item   \parbox[t]{0.75\textwidth}{Licensed under the \link{http://creativecommons.org/licenses/by-nc/4.0/}{Creative Commons Attribution-NonCommercial license}.
    Please share and remix non-commercially, mentioning its origin.}
    \parbox[c]{1.5cm}{\includegraphics[height=12pt]{../cc-by-nc}}
\item We acknowledge \link{https://jeswheel.github.io/4451_s26/acknowledge.html}{students and instructors for previous versions of this course / slides}.
\end{itemize}
}

\mode<presentation>{
\begin{frame}[allowframebreaks=0.8]{References and Acknowledgements}

\bibliography{../bib4451}

\vspace{3mm}

\acknowledgments

\end{frame}
}

\mode<article>{

\newpage

{\bf \Large \noindent Acknowledgments}

\acknowledgments

\newpage

\bibliography{../bib4451}

}



\end{document}







