\input{../header}

% \mode<beamer>{\usetheme{AnnArbor}}
\mode<beamer>{\usetheme{metropolis}}
\mode<beamer>{\metroset{block=fill}}
% \mode<beamer>{\usecolortheme{wolverine}}

\mode<beamer>{\setbeamertemplate{section in toc}[sections numbered]}
\mode<beamer>{\setbeamertemplate{subsection in toc}[subsections numbered indented]}

% \mode<beamer>{\usefonttheme{serif}}
\mode<beamer>{\setbeamertemplate{footline}}
\mode<beamer>{\setbeamertemplate{footline}[frame number]}
\mode<beamer>{\setbeamertemplate{frametitle continuation}[from second][\insertcontinuationcountroman]}
\mode<beamer>{\setbeamertemplate{navigation symbols}{}}

\mode<handout>{\pgfpagesuselayout{2 on 1}[letterpaper,border shrink=5mm]}

\newcommand\CHAPTER{1}
% \newcommand\answer[2]{\textcolor{blue}{#2}} % to show answers
% \newcommand\answer[2]{\textcolor{red}{#2}} % to show answers
 \newcommand\answer[2]{#1} % to show blank space

\title{\vspace{2mm} \link{https://jeswheel.github.io/4451_f25/}{Mathematical Statistics II}\\ \vspace{2mm}
Chapter \CHAPTER: Probability}
\author{Jesse Wheeler}
\date{}

\setbeamertemplate{footline}[frame number]

<<setup,include=FALSE,cache=FALSE,purl=FALSE,child="../setup.Rnw">>=
@

\begin{document}

\maketitle

\mode<article>{\tableofcontents}

% \mode<presentation>{
%   \begin{frame}{Outline}
%     \tableofcontents
%   \end{frame}
% }

\begin{frame}[allowframebreaks]{Course Overview}
  \begin{itemize}
    \item The larger focus of last semester (Math 4450) was probability.
    \item Though we continue where we left off, this semester (Math 4451) will have a much stronger focus on statistics.
    \item Both probability and statistics are, fundamentally, the study of with randomness... what's the difference? \mode<article>{\textbf{Depends on who you ask!}}
    
    \framebreak
    
    \mode<presentation>{
      \vspace{2cm}
    }
    
    \begin{quote}
      ``The science of collecting, displaying, and analysing data." -- \citet{OxfordStat}
    \end{quote}
    
    \mode<presentation>{
      \vfill
    }
    
    \begin{quote}
      ``The discipline that concerns the collection, organization, analysis, interpretation, and presentation of data." -- \citet{statsWiki}
    \end{quote}
    
    \mode<presentation>{
      \vfill
    }
    
    \begin{quote}
    Something like: ``The study of extracting useful information from data in a rigorous way." -- Me (it's hard to define an entire discipline).
    \end{quote}
    
  \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Probability vs Statistics}

\begin{itemize}
  \item Any of the above definitions (accurately) suggests that probability is a key part of statistics. So where do we draw the line? Does it matter?
  \item \citet{pawitan01} dichotomizes the difference in terms of \emph{deductive} vs \emph{inductive} reasoning.
  \item Roughly speaking, \emph{deductive} arguments moves from general principles (assumptions) to make specific conclusions.
  In \emph{inductive} reasoning, we use specific observations (data) to make broader generalizations.
\end{itemize}

\framebreak

\begin{exampleblock}{Traffic Accidents}
  Suppose we are interested in the random quantity $X_i$, the number of accidents during week $i$ at a particular intersection.
  From last semester, a common model for this situation is a Poisson-process.
\end{exampleblock}

\begin{itemize}
  \item \emph{Probability (deductive)}: If $X_i$ follows a Poisson$(\lambda)$ distribution (general principle), then what is the expected number of accidents per week (specific conclusion)? What is the probability that we observe more than $10$ accidents?
  
  \item \emph{Statistics (inductive)}: Suppose we count the number of accidents over a 6 week period, observing: $3, 4, 2, 7, 3, 3$ accidents (specific observations).
  What value $\lambda$ might describe the Poisson-process that generated the data (broader generalization)? Is the Poisson assumption reasonable given the data?
\end{itemize}

\begin{itemize}
  \item From the example above, we can see both ideas used in conjunction for making informed decisions.
  \item Many statistics problems rely on deductive reasoning in probability, geometry, topology, analysis, etc. to build theory for ways of performing inductive reasoning with specific observations (data).
  \item Another example related to my own research in population modeling...
\end{itemize}

<<echo=FALSE,include=FALSE,cache=TRUE>>=
library(tidyverse)

mylabs <- c("GIN"='Guinea', "LBR"="Liberia", "SLE"="Sierra Leone")

pomp::ebolaWA2014 %>%
  filter(date <= as.Date("2015-04-30")) %>% 
  ggplot(aes(x = date, y = cases)) + 
  geom_line() + 
  facet_wrap(~country, labeller = as_labeller(mylabs)) + 
  theme_bw() + 
  ylab("Ebola Cases") + 
  scale_x_date(date_labels = "%b-%y'") + 
  theme(axis.title.x = element_blank())

ggsave("ebola.png", width = 8, height = 2.65, units = 'in')
@

\begin{figure}[ht]
\includegraphics[width=\textwidth]{ebola.png}
\end{figure}

\begin{itemize}
  \item {\small (Statistics) Given the data (specific example), what can we learn about the dynamic system / generative process (generalization)?}
  \item {\small (Probability) Under our assumed process / model (general principle), what is our prediction for the Ebola burden over the next year (specific conclusion)?}
\end{itemize}

\end{frame}

\begin{frame}[allowframebreaks]{Statistics and Math 4451}

  \begin{itemize}
  \item \citet{pawitan01} further categorizes statistics in terms of five key `statistical activities' in the preface of his book:
    \begin{itemize}
      \item \emph{Planning}: making decisions about the study design or sampling protocol, what measurements to take, stratification, sample size, etc.
      \item \emph{Describing}: summarizing the bulk of data in few quantities, finding or revealing meaningful patterns or trends, etc. 
      \item \emph{Modeling}: developing mathematical models with few parameters to represent the patterns, or to explain the variability in terms of relationship between variables.
      \item \emph{Inference}: assessing whether we are seeing a real or spurious pattern or relationship, which typically involves an evaluation of the uncertainty in the parameter estimates.
      \item \emph{Model Checking}: assessing whether the model is sensible for the data.
    \end{itemize}
  \item A lot of early statistics were focused on the first two activities: \emph{planning} and \emph{describing}.
  We will not spend much time this semester discussing methods related to these two activities.
  \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Statistics and Uncertainty}
  \begin{itemize}
    \item Regardless of the type of ``statistical activity" we are doing, a recurring theme in statistics in \alert{uncertainty}.
    \item Loosely speaking, we can characterize two distinct forms of uncertainty:
    \begin{itemize}
      \item \emph{Stocahstic uncertainty}: uncertainty due to inherent randomness in data used to make inference, resulting in different models and estimates. For example, what if we picked different weeks to observe traffic patterns at the intersection? We would likely get different data, resulting in different parameter estimates.
      \item \emph{Inductive uncertainty}: uncertainty due to the inductive nature of our estimates. This is a result of having incomplete information (e.g., due traffic accidents at the intersection truly follow a Poisson-process?) We generally can't control this type of uncertainty, or even quantify it.
    \end{itemize}
    \item The first type can be thought of as the uncertainty present, conditioned on a specific model. The second is related to uncertainty involved in the model selection itself.
  \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Traffic Deaths}
  \begin{exampleblock}{Traffic Deaths and Cell-Phone usage}
    Suppose instead of measuring total accidents at an intersection, what if we model the total number of deaths? We might be interested in estimating how cell-phone usage might be correlated with number of traffic deaths.
  \end{exampleblock}
  
  \begin{itemize}
    \item Ideally, we would like to do a randomized experiment, placing drivers into a control (no cell-phone), or treatment group (cell-phone). \textit{Recall from Math 3350, this is the best way to control for confounding.}
    \item This isn't possible, so instead we rely on what is called a \alert{natural experiment}. The ``control" group will be the population of drivers the year before the invention of cell-phones, and the ``treatment" group is the population of drivers the year cell-phones were invented.
    \item Thought experiment: What if the number of deaths increase from 170 in one year, to 190 the next? Is this enough to claim cell-phones increase accidents? What about 170 to 300? 170 to 174? What's the cutoff?
    \framebreak
    
    \mode<article>{
    \begin{itemize}
      \item The question above is related to changes in observed data, not the model. That is, fixed on a model, we can make statements about what is considered a ``large enough" change in order to consider cell-phones having an impact.
    \end{itemize}
    }
    
    \item Now suppose the deaths increased from 170 to 300, but in the second year, a few major accident involved many cars, in which over 50 people died. 
    Alternatively, what if the second year had a much longer winter, or there were more teen drivers? What other factors might change how we think about this?
    
    \mode<article>{
    \begin{itemize}
      \item This time, uncertainty arises because of model choice. We can increase model detail by splitting by age, month, etc., but the data then fall into smaller and smaller groups, increasing the stochastic uncertainty. We have to stop adding detail at some point, but where?
    \end{itemize}
    }
  \end{itemize}
  
\end{frame}

\begin{frame}[allowframebreaks]{Frequentist vs Bayesian}
  \begin{itemize}
    \item When we finally settle down on a model, we can deal with the inherent stochastic uncertainty in the data in a rigorous way.
    \item Typically, this is done using probability.
    \item Probability is a surprisingly abstract topic, however, and how to connect real-world outcomes to probability is non-trivial.
    \item An at times frustrating (and possibly unique) feature of Statistics as a discipline is that experts cannot agree on the fundamental nature of their subject.
    \item There are two groups of thought: \alert{Bayesian} and \alert{Frequentist} perspective. We will discuss approaches from both in this class.
  \end{itemize}
  
  \framebreak
  
  In the extremes, interpretation of probability falls into two main categories:
  
  \begin{itemize}
    \item \alert{Bayesian} perspective: probabilities correspond to a (subjective) degree of belief about an event.
    \item \alert{Frequentist} perspective: probabilities are interpreted only in long-run frequency of events.
  \end{itemize}
  
  \begin{itemize}
    \item Note in the Bayesian perspective admits both perspectives, and many modern Bayesian approaches often consider the frequentist properties of their methods.
    \item In \textit{my experience}, most statisticians actually fall somewhere in the middle.
  \end{itemize}
  
  \framebreak
  
  \begin{exampleblock}{Tossing a coin}
    Consider tossing a fair coin. We have some sense of uncertainty about the outcome of this experiment, and say that the probability of heads is $0.5$.
  \end{exampleblock}
  
  \begin{itemize}
    \item In the extreme frequentist paradigm, this is interpreted to mean that the long-run proportion of heads (many coin flips) is $0.5$. However, interpreting the uncertainty of the next \emph{specific} toss is difficult (something like: the next toss belongs to an infinite sequence of tosses of the same coin, which have a limiting frequency of $0.5$.)
    
    \item In the extreme Bayesian paradigm, a $0.5$ probability corresponds to a \emph{belief} about the behavior of the coin; this belief can be entirely subjective. Saying a probability of $0.5$ means that even in the next specific coin toss, our sense of uncertainty is $0.5$.
  \end{itemize}
  
  \begin{itemize}
    \item \alert{Important}! Both approaches have their strengths and weaknesses, and some of the smartest scientists / mathematicians in the world can be found in either extreme.
    Though most statisticians will claim to think one-way versus the other, most fall somewhere in the middle (frequentists' will often be founding making subjective probability statements, whereas Bayesians' often admit to caring about frequentist properties of their methods).
    \item We will cover both approaches, and discuss strengths and weaknesses of each when relevant. However, the focus will be on frequentist statistics, as the vast majority of statistical methods in use in the 20th and 21st centuries are based on frequentism.
    \item There's also a ``third way", sometimes called \alert{Fisherian}, or \alert{likelihoodist}. To some degree this is a compromise between the two more popular approaches, as it rejects the use of prior distributions, but still interprets likelihood as a way to measure belief about a parameter estimate \citep{pawitan01}.
  \end{itemize}
  
\end{frame}

\newcommand\acknowledgments{
\begin{itemize}
\item   Compiled on {\today} using \Rlanguage version \Sexpr{getRversion()}.
\item   \parbox[t]{0.75\textwidth}{Licensed under the \link{http://creativecommons.org/licenses/by-nc/4.0/}{Creative Commons Attribution-NonCommercial license}.
    Please share and remix non-commercially, mentioning its origin.}
    \parbox[c]{1.5cm}{\includegraphics[height=12pt]{../cc-by-nc}}
\item We acknowledge \link{https://jeswheel.github.io/4451_s26/acknowledge.html}{students and instructors for previous versions of this course / slides}.
\end{itemize}
}

\mode<presentation>{
\begin{frame}[allowframebreaks=0.8]{References and Acknowledgements}
  
\bibliography{../bib4451}

\vspace{3mm}

\acknowledgments

\end{frame}
}

\mode<article>{

\newpage

{\bf \Large \noindent Acknowledgments}

\acknowledgments

\newpage

\bibliography{../bib4451}

}



\end{document}







